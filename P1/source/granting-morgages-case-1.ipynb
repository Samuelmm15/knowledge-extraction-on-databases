{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1 Extracción del conocimiento en bases de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se desea construir un sistema basado en Analítica de datos que\n",
    "ayude en la tarea de concesión de los créditos.\n",
    "\n",
    "## Tareas\n",
    "\n",
    "1. `Preparar los datos`. \n",
    "Desarrollar las tareas de prepararación de los\n",
    "datos necesarias para disponer de una base de datos apropiada\n",
    "para la tarea de clasificación. Entre las labores a realizar se encuentran las de visualización y comprensión de las variables, cambio de tipos, transformación e identificación de outliers y datos\n",
    "faltantes. También debe quedar claro si nos enfrentamos a una\n",
    "clasificación con clases balanceadas o no.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comenzar con la práctica, primero se importan las librerías necesarias y se carga el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de las distintas librerías necesarias y el dataset del que se hace uso\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Carga del dataset\n",
    "dataset = pd.read_csv('../data/Base de datos - homeLoanAproval.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez se tienen cargadas las distintas librerías de las cuales se va a hacer uso, y, el dataset, se procede a realizar los cambios de tipos, la transformación e identificación de outliers y datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loan_ID Gender Married  ... LoanAmountTerm PropertyArea LoanStatus\n",
      "0  LP001002   Male      No  ...          360.0        Urban          Y\n",
      "1  LP001003   Male     Yes  ...          360.0        Rural          N\n",
      "2  LP001005   Male     Yes  ...          360.0        Urban          Y\n",
      "3  LP001006   Male     Yes  ...          360.0        Urban          Y\n",
      "4  LP001008   Male      No  ...          360.0        Urban          Y\n",
      "\n",
      "[5 rows x 12 columns]\n",
      "\n",
      "Número de registros y columnas del dataset:  (614, 12)\n"
     ]
    }
   ],
   "source": [
    "# Una vez cargado el dataset, se procede a la visualización de los datos del dataset\n",
    "\n",
    "# Se visualizan los primeros 5 registros del dataset\n",
    "print(dataset.head())\n",
    "\n",
    "# Se visualiza la cantidad de registros y columnas del dataset\n",
    "print()\n",
    "print('Número de registros y columnas del dataset: ', dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tipos de datos de las columnas del dataset: \n",
      "Loan_ID               object\n",
      "Gender                object\n",
      "Married               object\n",
      "Dependents            object\n",
      "Education             object\n",
      "SelfEmployed          object\n",
      "ApplicantIncome        int64\n",
      "CoapplicantIncome     object\n",
      "LoanAmount           float64\n",
      "LoanAmountTerm       float64\n",
      "PropertyArea          object\n",
      "LoanStatus            object\n",
      "dtype: object\n",
      "\n",
      "Resumen estadístico de las columnas numéricas del dataset: \n",
      "       ApplicantIncome  LoanAmount  LoanAmountTerm\n",
      "count       614.000000  592.000000       600.00000\n",
      "mean       5403.459283  146.412162       342.00000\n",
      "std        6109.041673   85.587325        65.12041\n",
      "min         150.000000    9.000000        12.00000\n",
      "25%        2877.500000  100.000000       360.00000\n",
      "50%        3812.500000  128.000000       360.00000\n",
      "75%        5795.000000  168.000000       360.00000\n",
      "max       81000.000000  700.000000       480.00000\n"
     ]
    }
   ],
   "source": [
    "# Se identifican los tipos de datos de las columnas del dataset, además del significado de cada una de ellas\n",
    "print()\n",
    "print('Tipos de datos de las columnas del dataset: ')\n",
    "print(dataset.dtypes)\n",
    "\n",
    "# Se hace un resumen estadístico de las columnas numéricas del dataset\n",
    "print()\n",
    "print('Resumen estadístico de las columnas numéricas del dataset: ')\n",
    "print(dataset.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo en cuenta esto anterior, cabe destacar que el dataset se compone de 12 variables, de las cuales 11 son variables predictoras y 1 es la variable objetivo. Las variables predictoras son las siguientes:\n",
    "\n",
    "- `Loan_ID`: Identificador de la solicitud.\n",
    "- `Gender`: Género del solicitante.\n",
    "- `Married`: Estado civil del solicitante.\n",
    "- `Dependents`: Número de personas a cargo del solicitante.\n",
    "- `Education`: Nivel de educación del solicitante.\n",
    "- `Self_Employed`: Si el solicitante es autónomo o no.\n",
    "- `ApplicantIncome`: Ingresos del solicitante.\n",
    "- `CoapplicantIncome`: Ingresos del segundo solicitante del crédito.\n",
    "- `LoanAmount`: Cantidad del préstamo.\n",
    "- `LoanAmountTerm`: Plazo del préstamo (Medido en meses).\n",
    "- `PropertyArea`: Zona de la propiedad que se quiere hipotecar.\n",
    "- `LoanStatus`: Indica el estado de que se ha concedido o no el préstamo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores nulos de cada columna del dataset: \n",
      "Loan_ID               0\n",
      "Gender               13\n",
      "Married               3\n",
      "Dependents           15\n",
      "Education             0\n",
      "SelfEmployed         32\n",
      "ApplicantIncome       0\n",
      "CoapplicantIncome     0\n",
      "LoanAmount           22\n",
      "LoanAmountTerm       14\n",
      "PropertyArea          0\n",
      "LoanStatus            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Se identifican los valores nulos de cada columna del dataset\n",
    "print()\n",
    "print('Valores nulos de cada columna del dataset: ')\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo en cuenta los valores nulos que se encuentran en las distintas columnas anteriores, se procede a tomar decisiones o acciones dependiendo del tipo de variable que se trate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación de los datos nulos del dataset\n",
    "\n",
    "# Imputación de los valores que posteriormente se transfomarán en categóricos a través de la moda\n",
    "dataset['Gender'] = dataset['Gender'].fillna(dataset['Gender'].mode()[0])\n",
    "dataset['Married'] = dataset['Married'].fillna(dataset['Married'].mode()[0])\n",
    "dataset['SelfEmployed'] = dataset['SelfEmployed'].fillna(dataset['SelfEmployed'].mode()[0])\n",
    "\n",
    "# Imputación de los valores de la variable de Dependents a través de la moda\n",
    "dataset['Dependents'] = dataset['Dependents'].fillna(dataset['Dependents'].mode()[0])\n",
    "\n",
    "# Imputación de los valores de la variable de LoanAmount a través de la mediana\n",
    "dataset['LoanAmount'] = dataset['LoanAmount'].fillna(dataset['LoanAmount'].median())\n",
    "\n",
    "# Imputación de los valores de la variable de LoanAmountTerm a través de la moda\n",
    "dataset['LoanAmountTerm'] = dataset['LoanAmountTerm'].fillna(dataset['LoanAmountTerm'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambios de tipos de datos de las columnas del dataset para su correcto manejo\n",
    "\n",
    "# Conversión de columnas a tipo categórico, ya que este tipo para pandas es más eficiente que el tipo object, ya que se tratan de aquellas variables que pueden tomar un número limitado de valores distintos \n",
    "# Reemplazar valores no válidos en la columna 'Dependents'\n",
    "dataset['Dependents'] = dataset['Dependents'].replace('3+', 3)\n",
    "\n",
    "# Conversión de Dependents a tipo entero (int64)\n",
    "dataset['Dependents'] = dataset['Dependents'].astype('int64')\n",
    "\n",
    "# Conversión de columnas a tipo categórico\n",
    "dataset['Gender'] = dataset['Gender'].astype('category')\n",
    "dataset['Married'] = dataset['Married'].astype('category')\n",
    "dataset['Education'] = dataset['Education'].astype('category')\n",
    "dataset['SelfEmployed'] = dataset['SelfEmployed'].astype('category')\n",
    "dataset['PropertyArea'] = dataset['PropertyArea'].astype('category')\n",
    "dataset['LoanStatus'] = dataset['LoanStatus'].astype('category')\n",
    "\n",
    "# # Conversión de CoapplicantIncome a tipo numérico (float64)\n",
    "dataset['CoapplicantIncome'] = dataset['CoapplicantIncome'].str.replace('.', '', regex=False)\n",
    "dataset['CoapplicantIncome'] = pd.to_numeric(dataset['CoapplicantIncome'], errors='coerce')\n",
    "\n",
    "# Conversión de LoanAmountTerm a tipo entero\n",
    "dataset['LoanAmountTerm'] = dataset['LoanAmountTerm'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Analizar los datos. Construir un clasificador k-NN, un árbol de\n",
    "clasificación y un clasificador naive Bayes. Se propone considerar\n",
    "varios escenarios. En el primero, independientemente de que existan o no datos faltantes o outliers, se aplicará el correspondiente\n",
    "algoritmo de inducción sin tener en cuenta estos hechos. En el segundo escenario, se aplicarán técnicas para tratar con los outliers\n",
    "y los datos faltantes y se construirán los anteriores clasificadores.\n",
    "Debe evaluarse también el uso de técnicas para tratar con clases desbalanceadas y el efecto que tienen estas técnicas en la calidad de los clasificadores obtenidos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score train: 0.7617107942973523\n",
      "Accuracy score test: 0.6260162601626016\n",
      "[[ 6 37]\n",
      " [ 9 71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.40      0.14      0.21        43\n",
      "           Y       0.66      0.89      0.76        80\n",
      "\n",
      "    accuracy                           0.63       123\n",
      "   macro avg       0.53      0.51      0.48       123\n",
      "weighted avg       0.57      0.63      0.56       123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Convertir columnas categóricas a variables dummy (para que sean tratadas como variables numéricas)\n",
    "X = pd.get_dummies(dataset.drop('LoanStatus', axis=1))\n",
    "y = dataset['LoanStatus']\n",
    "\n",
    "# Dividir el dataset en conjunto de entrenamiento y conjunto de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar las características\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Crear el clasificador k-NN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Entrenar el clasificador\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred = knn.predict(X_test)\n",
    "y_pred_train = knn.predict(X_train)\n",
    "\n",
    "# Evaluar el clasificador\n",
    "print(\"Accuracy score train: {}\".format(accuracy_score(y_train, y_pred_train)))\n",
    "print(\"Accuracy score test: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "# Evaluar el clasificador\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador Árbol de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 43]\n",
      " [ 3 77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.00      0.00      0.00        43\n",
      "           Y       0.64      0.96      0.77        80\n",
      "\n",
      "    accuracy                           0.63       123\n",
      "   macro avg       0.32      0.48      0.39       123\n",
      "weighted avg       0.42      0.63      0.50       123\n",
      "\n"
     ]
    },
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/knowledge-extraction-on-databases/P1/lib/python3.12/site-packages/graphviz/backend/execute.py:78\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m         proc \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/subprocess.py:1955\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1955\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: PosixPath('dot')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Visualizar el árbol de decisión\u001b[39;00m\n\u001b[1;32m     27\u001b[0m graph \u001b[38;5;241m=\u001b[39m graphviz\u001b[38;5;241m.\u001b[39mSource(dot_data)  \n\u001b[0;32m---> 28\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecision_tree\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Esto guardará el árbol como un archivo PDF llamado \"decision_tree.pdf\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m graph\n",
      "File \u001b[0;32m~/Documents/knowledge-extraction-on-databases/P1/lib/python3.12/site-packages/graphviz/_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/knowledge-extraction-on-databases/P1/lib/python3.12/site-packages/graphviz/rendering.py:122\u001b[0m, in \u001b[0;36mRender.render\u001b[0;34m(self, filename, directory, view, cleanup, format, renderer, formatter, neato_no_op, quiet, quiet_view, outfile, engine, raise_if_result_exists, overwrite_source)\u001b[0m\n\u001b[1;32m    118\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(filename, directory\u001b[38;5;241m=\u001b[39mdirectory, skip_existing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    120\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(filepath)\n\u001b[0;32m--> 122\u001b[0m rendered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[1;32m    125\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelete \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, filepath)\n",
      "File \u001b[0;32m~/Documents/knowledge-extraction-on-databases/P1/lib/python3.12/site-packages/graphviz/_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/knowledge-extraction-on-databases/P1/lib/python3.12/site-packages/graphviz/backend/rendering.py:326\u001b[0m, in \u001b[0;36mrender\u001b[0;34m(engine, format, filepath, renderer, formatter, neato_no_op, quiet, outfile, raise_if_result_exists, overwrite_filepath)\u001b[0m\n\u001b[1;32m    322\u001b[0m cmd \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m filepath \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwork around pytype false alarm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 326\u001b[0m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mfspath(outfile)\n",
      "File \u001b[0;32m~/Documents/knowledge-extraction-on-databases/P1/lib/python3.12/site-packages/graphviz/backend/execute.py:81\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "# Crear el clasificador de árbol de decisión con hiperparámetros ajustados\n",
    "tree_clf = DecisionTreeClassifier(random_state=42, max_depth=3, min_samples_split=10, min_samples_leaf=5)\n",
    "\n",
    "# Entrenar el clasificador\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "\n",
    "# Evaluar el clasificador\n",
    "print(confusion_matrix(y_test, y_pred_tree))\n",
    "print(classification_report(y_test, y_pred_tree))\n",
    "\n",
    "# Exportar el árbol de decisión a un archivo DOT\n",
    "dot_data = tree.export_graphviz(tree_clf, out_file=None, \n",
    "                                feature_names=X.columns,  \n",
    "                                class_names=tree_clf.classes_,  \n",
    "                                filled=True, rounded=True,  \n",
    "                                special_characters=True)  \n",
    "\n",
    "# Visualizar el árbol de decisión\n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph.render(\"decision_tree\")  # Esto guardará el árbol como un archivo PDF llamado \"decision_tree.pdf\"\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43  0]\n",
      " [80  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.35      1.00      0.52        43\n",
      "           Y       1.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.35       123\n",
      "   macro avg       0.67      0.50      0.26       123\n",
      "weighted avg       0.77      0.35      0.18       123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Crear el clasificador Naive Bayes\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "# Entrenar el clasificador\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_nb = nb_clf.predict(X_test)\n",
    "\n",
    "# Evaluar el clasificador\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb, zero_division=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
